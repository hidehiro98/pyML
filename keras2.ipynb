{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10データの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3384s  \n",
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ed8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(toimage(X_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,618,602\n",
      "Trainable params: 1,618,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 137s - loss: 14.4985 - acc: 0.1004   \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.506285702514649, 0.10000000000000001]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 転移学習\n",
    "\n",
    "すでに学習済みのモデルを利用して、新しい画像の分類を行う。\n",
    "\n",
    "Kerasでは、\n",
    "\n",
    "単に学習済みのものを用いて分類させるだけであれば、以下のようにできる。ただしimagenetにある画像を用いて学習しており、教師データにない画像は判別できない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "  1515520/553467096 [..............................] - ETA: 16832s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0874a2654d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./image/apple2.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    163\u001b[0m             weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n\u001b[1;32m    164\u001b[0m                                     \u001b[0mWEIGHTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                                     cache_subdir='models')\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sugakubunka/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "img = image.load_img(\"./image/apple2.jpg\", target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = model.predict(preprocess_input(x))\n",
    "results = decode_predictions(preds, top=5)[0]\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この学習済みモデルを利用して、一部分のパラメータを再学習させることにより画像の分類を行うことができる。このような手法を転移学習とかFine tuningなどという。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`include_top=False`とすることで、最後の全結合から分類の層を除いたモデルを作ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "model = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各層ごとにパラメータを学習させるかさせないかを設定できる。ここでは畳み込み層は全て学習しないことにしてみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 133,898\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 10)                133898    \n",
      "=================================================================\n",
      "Total params: 14,848,586\n",
      "Trainable params: 133,898\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = Sequential()\n",
    "for l in model.layers:\n",
    "    new_model.add(l)\n",
    "\n",
    "new_model.add(top_model)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 1449s 32ms/step - loss: 10.8011 - acc: 0.3140 - val_loss: 10.3268 - val_acc: 0.3498\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "history = new_model.fit(X_train, y_train, validation_split=0.1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 291s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.33102604675293, 0.34899999999999998]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "new_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習\n",
    "\n",
    "fasion MNISTやCIFAR100で同様の学習を行ってみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augumentation\n",
    "\n",
    "入手できるデータが少数の場合などに、取り込んだ画像から類似の画像を生成して、学習データを増やすことができる。\n",
    "\n",
    "また過学習に対処することができる。\n",
    "- ネットワークを単純にする\n",
    "- データを増やす。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "img = load_img(\"./image/apple1.jpg\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='image', save_prefix='apple', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを用いて学習データを生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/10\n",
      "1562/1562 [==============================] - 428s 274ms/step - loss: 1.8884 - acc: 0.3032 - val_loss: 1.5746 - val_acc: 0.4429\n",
      "Epoch 2/10\n",
      "1562/1562 [==============================] - 445s 285ms/step - loss: 1.5866 - acc: 0.4196 - val_loss: 1.3967 - val_acc: 0.4935\n",
      "Epoch 3/10\n",
      "1562/1562 [==============================] - 437s 279ms/step - loss: 1.4587 - acc: 0.4714 - val_loss: 1.2964 - val_acc: 0.5319\n",
      "Epoch 4/10\n",
      "1562/1562 [==============================] - 436s 279ms/step - loss: 1.3757 - acc: 0.5057 - val_loss: 1.2071 - val_acc: 0.5771\n",
      "Epoch 5/10\n",
      "1562/1562 [==============================] - 434s 278ms/step - loss: 1.3001 - acc: 0.5326 - val_loss: 1.1598 - val_acc: 0.5864\n",
      "Epoch 6/10\n",
      "1562/1562 [==============================] - 435s 278ms/step - loss: 1.2350 - acc: 0.5608 - val_loss: 1.1046 - val_acc: 0.6122\n",
      "Epoch 7/10\n",
      "1562/1562 [==============================] - 431s 276ms/step - loss: 1.1804 - acc: 0.5814 - val_loss: 1.0094 - val_acc: 0.6449\n",
      "Epoch 8/10\n",
      "1562/1562 [==============================] - 434s 278ms/step - loss: 1.1375 - acc: 0.5969 - val_loss: 0.9800 - val_acc: 0.6561\n",
      "Epoch 9/10\n",
      "1562/1562 [==============================] - 438s 280ms/step - loss: 1.0968 - acc: 0.6121 - val_loss: 0.9503 - val_acc: 0.6653\n",
      "Epoch 10/10\n",
      "1562/1562 [==============================] - 447s 286ms/step - loss: 1.0629 - acc: 0.6262 - val_loss: 0.9080 - val_acc: 0.6821\n",
      "Saved trained model at /Users/naoya/repos/bunka/pythonML/saved_models/keras_cifar10_trained_model.h5 \n",
      "Model Accuracy = 0.66\n",
      "Actual Label = cat vs. Predicted Label = automobile\n",
      "Actual Label = ship vs. Predicted Label = frog\n",
      "Actual Label = ship vs. Predicted Label = dog\n",
      "Actual Label = airplane vs. Predicted Label = bird\n",
      "Actual Label = frog vs. Predicted Label = horse\n",
      "Actual Label = frog vs. Predicted Label = airplane\n",
      "Actual Label = automobile vs. Predicted Label = dog\n",
      "Actual Label = frog vs. Predicted Label = bird\n",
      "Actual Label = cat vs. Predicted Label = airplane\n",
      "Actual Label = automobile vs. Predicted Label = ship\n",
      "Actual Label = airplane vs. Predicted Label = bird\n",
      "Actual Label = truck vs. Predicted Label = cat\n",
      "Actual Label = dog vs. Predicted Label = truck\n",
      "Actual Label = horse vs. Predicted Label = bird\n",
      "Actual Label = truck vs. Predicted Label = ship\n",
      "Actual Label = ship vs. Predicted Label = ship\n",
      "Actual Label = dog vs. Predicted Label = truck\n",
      "Actual Label = horse vs. Predicted Label = automobile\n",
      "Actual Label = ship vs. Predicted Label = frog\n",
      "Actual Label = frog vs. Predicted Label = deer\n",
      "Actual Label = horse vs. Predicted Label = ship\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Load label names to use in prediction results\n",
    "label_list_path = 'datasets/cifar-10-batches-py/batches.meta'\n",
    "\n",
    "\n",
    "keras_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
    "datadir_base = os.path.expanduser(keras_dir)\n",
    "if not os.access(datadir_base, os.W_OK):\n",
    "    datadir_base = os.path.join('/tmp', '.keras')\n",
    "label_list_path = os.path.join(datadir_base, label_list_path)\n",
    "\n",
    "with open(label_list_path, mode='rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "\n",
    "# Evaluate model with test data set and share sample prediction results\n",
    "evaluation = model.evaluate_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "print('Model Accuracy = %.2f' % (evaluation[1]))\n",
    "\n",
    "predict_gen = model.predict_generator(datagen.flow(x_test, y_test,\n",
    "                                      batch_size=batch_size),\n",
    "                                      steps=x_test.shape[0] // batch_size)\n",
    "\n",
    "for predict_index, predicted_y in enumerate(predict_gen):\n",
    "    actual_label = labels['label_names'][np.argmax(y_test[predict_index])]\n",
    "    predicted_label = labels['label_names'][np.argmax(predicted_y)]\n",
    "    print('Actual Label = %s vs. Predicted Label = %s' % (actual_label,\n",
    "                                                          predicted_label))\n",
    "    if predict_index == num_predictions:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像の分類\n",
    "\n",
    "ここでは自分で取り込んだ画像の分類を行なってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 100, 100, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.backend(), K.image_dim_ordering()\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "img = []\n",
    "label = []\n",
    "for d in ['apple','tomato','melon']:\n",
    "    for n in range(20):\n",
    "        img.append(img_to_array(load_img(\"./image/%s%s.jpg\" % (d,n+1),\n",
    "                                         target_size=(100,100)))/255)\n",
    "        label.append(d)\n",
    "        \n",
    "import numpy as np\n",
    "X_total = np.array(img)\n",
    "X = np.concatenate((X_total[:20,],X_total[20:40,]))\n",
    "y = np.array([0]*20+[1]*20)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 30976)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               7930112   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,995,937\n",
      "Trainable params: 7,995,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 3s 89ms/step - loss: 1.0325 - acc: 0.4643\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.7544 - acc: 0.4643\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 2s 72ms/step - loss: 0.6745 - acc: 0.6786\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.6878 - acc: 0.5357\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 0.6876 - acc: 0.5357\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 0.6916 - acc: 0.5357\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.6778 - acc: 0.5357\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.6829 - acc: 0.5357\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 2s 69ms/step - loss: 0.6685 - acc: 0.5357\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.6705 - acc: 0.5357\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1022a6588>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRUQCSOUuIhJA/wPNWcIrs1lHlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11168bf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "acc_values = history_dict['acc']\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.plot(acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "12/12 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.71602672338485718, 0.4166666567325592]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.7810 - acc: 0.5893\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.7054 - acc: 0.5227\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.6636 - acc: 0.5600\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.5911 - acc: 0.6667\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 3s 314ms/step - loss: 0.6006 - acc: 0.5227\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 3s 319ms/step - loss: 0.4892 - acc: 0.7760\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 3s 315ms/step - loss: 0.6187 - acc: 0.6696\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.3728 - acc: 0.8519\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.3819 - acc: 0.7449\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 0.2128 - acc: 0.9630\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 3s 317ms/step - loss: 0.1464 - acc: 0.9253\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 3s 316ms/step - loss: 0.8292 - acc: 0.8880\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 3s 355ms/step - loss: 0.3371 - acc: 0.8507\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 3s 360ms/step - loss: 0.4283 - acc: 0.7778\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 3s 341ms/step - loss: 0.2778 - acc: 0.8870\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 0.2913 - acc: 0.9253\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 3s 347ms/step - loss: 0.2519 - acc: 0.8889\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.4590 - acc: 0.8507\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 0.2188 - acc: 0.8880\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 3s 326ms/step - loss: 0.1468 - acc: 0.9627\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 3\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "history = model2.fit_generator(datagen.flow(X_train, y_train,\n",
    "                                 batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x114e95be0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b2c0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "acc_values = history_dict['acc']\n",
    "\n",
    "plt.plot(loss_values)\n",
    "plt.plot(acc_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.50666838511824608, 0.8333333358168602]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate_generator(datagen.flow(X_test, y_test,\n",
    "                                 batch_size=batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
