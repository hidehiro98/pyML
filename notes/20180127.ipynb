{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:100, :]\n",
    "y = iris.target[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, activation='sigmoid', input_dim=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2334 - acc: 0.5222\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 62us/step - loss: 1.9683 - acc: 0.5222\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 66us/step - loss: 1.7041 - acc: 0.5222\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 73us/step - loss: 1.4529 - acc: 0.5222\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 102us/step - loss: 1.2169 - acc: 0.5222\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 76us/step - loss: 1.0025 - acc: 0.5222\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 74us/step - loss: 0.8160 - acc: 0.5222\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 75us/step - loss: 0.6653 - acc: 0.5222\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 95us/step - loss: 0.5501 - acc: 0.5222\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 77us/step - loss: 0.4665 - acc: 0.5444\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 109us/step - loss: 0.4101 - acc: 0.6778\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 98us/step - loss: 0.3743 - acc: 0.9111\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 248us/step - loss: 0.3512 - acc: 0.9778\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 180us/step - loss: 0.3362 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 148us/step - loss: 0.3271 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 0s 99us/step - loss: 0.3193 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 0s 60us/step - loss: 0.3133 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 0s 105us/step - loss: 0.3087 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 0s 114us/step - loss: 0.3041 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 0s 174us/step - loss: 0.2999 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "history = model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 202us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29729352527194552, 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## irisの全クラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=3, activation='softmax', input_dim=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.4441 - acc: 0.9037\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 0s 59us/step - loss: 0.4429 - acc: 0.8815\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 0s 49us/step - loss: 0.4370 - acc: 0.9037\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 0s 55us/step - loss: 0.4351 - acc: 0.9037\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 0s 53us/step - loss: 0.4342 - acc: 0.9259\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 0s 54us/step - loss: 0.4353 - acc: 0.9037\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 0s 112us/step - loss: 0.4397 - acc: 0.8519\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 0s 132us/step - loss: 0.4308 - acc: 0.8963\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 0s 94us/step - loss: 0.4337 - acc: 0.8815\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 0s 230us/step - loss: 0.4288 - acc: 0.9185\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 0s 98us/step - loss: 0.4268 - acc: 0.9111\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 0s 116us/step - loss: 0.4273 - acc: 0.9037\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 0s 100us/step - loss: 0.4276 - acc: 0.9111\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 0s 175us/step - loss: 0.4249 - acc: 0.9111\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 0s 92us/step - loss: 0.4254 - acc: 0.8963\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 0s 193us/step - loss: 0.4277 - acc: 0.8963\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 0s 83us/step - loss: 0.4237 - acc: 0.9111\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 0s 65us/step - loss: 0.4221 - acc: 0.9185\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.4218 - acc: 0.9111\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 0s 112us/step - loss: 0.4225 - acc: 0.9111\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 0s 79us/step - loss: 0.4163 - acc: 0.9259\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 0s 95us/step - loss: 0.4150 - acc: 0.9185\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 0s 66us/step - loss: 0.4147 - acc: 0.9259\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 0s 54us/step - loss: 0.4206 - acc: 0.9037\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 0s 48us/step - loss: 0.4124 - acc: 0.9259\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 0s 70us/step - loss: 0.4100 - acc: 0.9111\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 0s 51us/step - loss: 0.4109 - acc: 0.9185\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 0s 70us/step - loss: 0.4092 - acc: 0.9185\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 0s 71us/step - loss: 0.4079 - acc: 0.9407\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 0s 50us/step - loss: 0.4083 - acc: 0.9185\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 0s 65us/step - loss: 0.4098 - acc: 0.9111\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 0s 68us/step - loss: 0.4052 - acc: 0.9185\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 0s 47us/step - loss: 0.4063 - acc: 0.8963\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 0s 72us/step - loss: 0.4068 - acc: 0.9185\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 0s 63us/step - loss: 0.4030 - acc: 0.9333\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 0s 48us/step - loss: 0.4071 - acc: 0.9407\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 0s 60us/step - loss: 0.4005 - acc: 0.9111\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 0s 68us/step - loss: 0.4013 - acc: 0.9259\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 0s 60us/step - loss: 0.3984 - acc: 0.9185\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 0s 51us/step - loss: 0.3982 - acc: 0.9185\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 0s 96us/step - loss: 0.3983 - acc: 0.9185\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 0s 50us/step - loss: 0.3975 - acc: 0.9333\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 0s 53us/step - loss: 0.3972 - acc: 0.9185\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 0s 118us/step - loss: 0.3947 - acc: 0.9259\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 0s 53us/step - loss: 0.3933 - acc: 0.9037\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.3930 - acc: 0.9259\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4412 - acc: 0.875 - 0s 83us/step - loss: 0.3937 - acc: 0.9259\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 0s 51us/step - loss: 0.3944 - acc: 0.9185\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.3899 - acc: 0.9333\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 0s 64us/step - loss: 0.3884 - acc: 0.9259\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 0s 78us/step - loss: 0.3881 - acc: 0.9407\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 0s 54us/step - loss: 0.3912 - acc: 0.9333\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.3884 - acc: 0.9111\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 0s 66us/step - loss: 0.3857 - acc: 0.9259\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 0s 78us/step - loss: 0.3849 - acc: 0.9481\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 0s 46us/step - loss: 0.3842 - acc: 0.9259\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 0s 66us/step - loss: 0.3832 - acc: 0.9333\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3954 - acc: 0.906 - 0s 65us/step - loss: 0.3827 - acc: 0.9259\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 0s 47us/step - loss: 0.3843 - acc: 0.9333\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.3804 - acc: 0.9333\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 0s 60us/step - loss: 0.3818 - acc: 0.9259\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 0s 73us/step - loss: 0.3820 - acc: 0.9259\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 0s 96us/step - loss: 0.3790 - acc: 0.9259\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 0s 64us/step - loss: 0.3784 - acc: 0.9259\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 0s 87us/step - loss: 0.3773 - acc: 0.9185\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 0s 49us/step - loss: 0.3768 - acc: 0.9333\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 0s 55us/step - loss: 0.3785 - acc: 0.9259\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 0s 57us/step - loss: 0.3758 - acc: 0.9259\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 0s 70us/step - loss: 0.3743 - acc: 0.9259\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 0s 57us/step - loss: 0.3736 - acc: 0.9407\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 0s 68us/step - loss: 0.3720 - acc: 0.9259\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 0s 100us/step - loss: 0.3711 - acc: 0.9333\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 0s 52us/step - loss: 0.3708 - acc: 0.9333\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.3711 - acc: 0.9407\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 0s 63us/step - loss: 0.3718 - acc: 0.9333\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 0s 54us/step - loss: 0.3712 - acc: 0.9259\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 0s 51us/step - loss: 0.3671 - acc: 0.9259\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 0s 57us/step - loss: 0.3659 - acc: 0.9407\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 0s 73us/step - loss: 0.3704 - acc: 0.9481\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 0s 53us/step - loss: 0.3646 - acc: 0.9407\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 0s 45us/step - loss: 0.3686 - acc: 0.9407\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.3633 - acc: 0.9407\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 60us/step - loss: 0.3631 - acc: 0.9481\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 0s 50us/step - loss: 0.3638 - acc: 0.9333\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 0s 52us/step - loss: 0.3629 - acc: 0.9259\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.3623 - acc: 0.9407\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 0s 88us/step - loss: 0.3616 - acc: 0.9481\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 0s 56us/step - loss: 0.3606 - acc: 0.9407\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 0s 53us/step - loss: 0.3589 - acc: 0.9333\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 0s 54us/step - loss: 0.3580 - acc: 0.9407\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 0s 74us/step - loss: 0.3580 - acc: 0.9407\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - 0s 65us/step - loss: 0.3579 - acc: 0.9556\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 0s 55us/step - loss: 0.3575 - acc: 0.9333\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 0s 61us/step - loss: 0.3586 - acc: 0.9481\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 0s 75us/step - loss: 0.3585 - acc: 0.9259\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - 0s 67us/step - loss: 0.3555 - acc: 0.9333\n",
      "Epoch 97/100\n",
      "135/135 [==============================] - 0s 52us/step - loss: 0.3567 - acc: 0.9481\n",
      "Epoch 98/100\n",
      "135/135 [==============================] - 0s 69us/step - loss: 0.3540 - acc: 0.9407\n",
      "Epoch 99/100\n",
      "135/135 [==============================] - 0s 60us/step - loss: 0.3527 - acc: 0.9407\n",
      "Epoch 100/100\n",
      "135/135 [==============================] - 0s 50us/step - loss: 0.3514 - acc: 0.9481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "history = model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hidehiro/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', input_dim=4))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a1eed3128>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADbBJREFUeJzt3W+sVPWdx/HPByyJq8WAfygRVtgGzTYbxAbNqhtlgyUs\nT7APaCRa2WzjNWtNtkk3WeMTzZImurHd7YO1ya0SMFK7JoiSprYlZKPbRAkXYyp/BAxBeoFAjWuK\nwdqg331wD90r3jkzzJwzZ+79vl8JmZnznTPzzQmf+ztnzpn5OSIEIJ9pTTcAoBmEH0iK8ANJEX4g\nKcIPJEX4gaQIP5AU4UdLthfZ/oPtZ5vuBdUj/Cjzn5J2Nd0E6kH4MSHbd0n6QNKOpntBPQg/Psf2\nTEn/Kum7TfeC+hB+TGS9pKcj4rdNN4L6XNR0AxgstpdIukPSDU33gnoRfpxvmaQFko7alqRLJU23\n/ZWI+GqDfaFi5iu9GM/2n0maOW7RP2vsj8E/RsTvGmkKtWDkx2dExBlJZ849tv2hpD8Q/KmHkR9I\nik/7gaQIP5AU4QeSIvxAUn39tN82ny4CNYsId/K8nkZ+2yttH7D9ju2HenktAP3V9ak+29MlHZT0\nNUmjGvvq59qI2FeyDiM/ULN+jPw3SXonIg5HxB8l/VTS6h5eD0Af9RL+qyWN/9bXaLHsM2wP2R6x\nPdLDewGoWC8f+E20a/G53fqIGJY0LLHbDwySXkb+UUnzxz2eJ+l4b+0A6Jdewr9L0iLbC23PkHSX\npG3VtAWgbl3v9kfEWdsPSvqlpOmSNkTE3so6A1Crvn6rj2N+oH59ucgHwORF+IGkCD+QFOEHkiL8\nQFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii\n/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJdT9ENDLrly5e3rG3evLl03dtvv720fuDA\nga56GiQ9hd/2EUmnJX0i6WxELK2iKQD1q2Lk/9uIeK+C1wHQRxzzA0n1Gv6Q9Cvbu20PTfQE20O2\nR2yP9PheACrU627/rRFx3PZVkrbbfjsiXh3/hIgYljQsSbajx/cDUJGeRv6IOF7cnpK0VdJNVTQF\noH5dh9/2Jba/eO6+pBWS9lTVGIB69bLbP0fSVtvnXucnEfGLSrqqwW233VZav/zyy0vrW7durbId\n9MGNN97YsrZr164+djKYug5/RByWdH2FvQDoI071AUkRfiApwg8kRfiBpAg/kFSar/QuW7astL5o\n0aLSOqf6Bs+0aeVj18KFC1vWrrnmmtJ1i1PYUxojP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kleY8\n/7333ltaf+211/rUCaoyd+7c0vp9993Xsvbss8+Wrvv222931dNkwsgPJEX4gaQIP5AU4QeSIvxA\nUoQfSIrwA0mlOc/f7rvfmHyeeuqprtc9dOhQhZ1MTiQCSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ka\nMuf5Fy9eXFqfM2dOnzpBv1x22WVdr7t9+/YKO5mc2o78tjfYPmV7z7hls21vt32ouJ1Vb5sAqtbJ\nbv9GSSvPW/aQpB0RsUjSjuIxgEmkbfgj4lVJ75+3eLWkTcX9TZLurLgvADXr9ph/TkSckKSIOGH7\nqlZPtD0kaajL9wFQk9o/8IuIYUnDkmQ76n4/AJ3p9lTfSdtzJam4PVVdSwD6odvwb5O0rri/TtJL\n1bQDoF/a7vbbfk7SMklX2B6V9IikxyQ9b/tbko5KWlNnk51YtWpVaf3iiy/uUyeoSrtrMxYuXNj1\nax87dqzrdaeKtuGPiLUtSssr7gVAH3F5L5AU4QeSIvxAUoQfSIrwA0lNma/0XnfddT2tv3fv3oo6\nQVWeeOKJ0nq7U4EHDx5sWTt9+nRXPU0ljPxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kNSUOc/fq127\ndjXdwqQ0c+bM0vrKlef/9uv/u+eee0rXXbFiRVc9nbN+/fqWtQ8++KCn154KGPmBpAg/kBThB5Ii\n/EBShB9IivADSRF+ICnO8xdmz57d2Htff/31pXXbpfU77rijZW3evHml686YMaO0fvfdd5fWp00r\nHz8++uijlrWdO3eWrvvxxx+X1i+6qPy/7+7du0vr2THyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS\njoj+vZld25s9+eSTpfX777+/tN7u+91Hjx694J46tXjx4tJ6u/P8Z8+ebVk7c+ZM6br79u0rrbc7\nFz8yMlJaf+WVV1rWTp48Wbru6OhoaX3WrFml9XbXMExVEVH+H6bQduS3vcH2Kdt7xi171PYx228W\n/1b10iyA/utkt3+jpIl+juXfI2JJ8e/n1bYFoG5twx8Rr0p6vw+9AOijXj7we9D2b4rDgpYHX7aH\nbI/YLj84BNBX3Yb/R5K+LGmJpBOSvt/qiRExHBFLI2Jpl+8FoAZdhT8iTkbEJxHxqaQfS7qp2rYA\n1K2r8NueO+7h1yXtafVcAIOp7ff5bT8naZmkK2yPSnpE0jLbSySFpCOSyk+i98EDDzxQWn/33XdL\n67fcckuV7VyQdtcQvPjii6X1/fv3t6y9/vrrXfXUD0NDQ6X1K6+8srR++PDhKttJp234I2LtBIuf\nrqEXAH3E5b1AUoQfSIrwA0kRfiApwg8kleanux9//PGmW8B5li9f3tP6W7ZsqaiTnBj5gaQIP5AU\n4QeSIvxAUoQfSIrwA0kRfiCpNOf5MfVs3bq16RYmNUZ+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKqTKbrnS3pG0pckfSppOCJ+aHu2pP+StEBj03R/\nIyL+t75WkY3t0vq1115bWh/k6ckHQScj/1lJ342Iv5T015K+bfsrkh6StCMiFknaUTwGMEm0DX9E\nnIiIN4r7pyXtl3S1pNWSNhVP2yTpzrqaBFC9Czrmt71A0g2SdkqaExEnpLE/EJKuqro5APXp+Df8\nbF8qaYuk70TE79sdj41bb0jSUHftAahLRyO/7S9oLPibI+KFYvFJ23OL+lxJpyZaNyKGI2JpRCyt\nomEA1Wgbfo8N8U9L2h8RPxhX2iZpXXF/naSXqm8PQF062e2/VdI3Jb1l+81i2cOSHpP0vO1vSToq\naU09LSKriCitT5vGZSq9aBv+iPi1pFYH+L1NsA6gMfzpBJIi/EBShB9IivADSRF+ICnCDyTFFN2Y\ntG6++ebS+saNG/vTyCTFyA8kRfiBpAg/kBThB5Ii/EBShB9IivADSXGeHwOr05+KQ3cY+YGkCD+Q\nFOEHkiL8QFKEH0iK8ANJEX4gKc7zozEvv/xyaX3NGqaCqBMjP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8k5XZzoNueL+kZSV+S9Kmk4Yj4oe1HJd0n6XfFUx+OiJ+3ea3yNwPQs4jo6IcQOgn/XElzI+IN\n21+UtFvSnZK+IenDiHii06YIP1C/TsPf9gq/iDgh6URx/7Tt/ZKu7q09AE27oGN+2wsk3SBpZ7Ho\nQdu/sb3B9qwW6wzZHrE90lOnACrVdrf/T0+0L5X0iqTvRcQLtudIek9SSFqvsUODf2jzGuz2AzWr\n7Jhfkmx/QdLPJP0yIn4wQX2BpJ9FxF+1eR3CD9Ss0/C33e332E+oPi1p//jgFx8EnvN1SXsutEkA\nzenk0/6/kfQ/kt7S2Kk+SXpY0lpJSzS2239E0v3Fh4Nlr8XID9Ss0t3+qhB+oH6V7fYDmJoIP5AU\n4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSfV7iu73JL077vEVxbJB\nNKi9DWpfEr11q8rerun0iX39Pv/n3tweiYiljTVQYlB7G9S+JHrrVlO9sdsPJEX4gaSaDv9ww+9f\nZlB7G9S+JHrrViO9NXrMD6A5TY/8ABpC+IGkGgm/7ZW2D9h+x/ZDTfTQiu0jtt+y/WbT8wsWcyCe\nsr1n3LLZtrfbPlTcTjhHYkO9PWr7WLHt3rS9qqHe5tv+b9v7be+1/U/F8ka3XUlfjWy3vh/z254u\n6aCkr0kalbRL0tqI2NfXRlqwfUTS0oho/IIQ27dJ+lDSM+emQrP9b5Lej4jHij+csyLiXwakt0d1\ngdO219Rbq2nl/14Nbrsqp7uvQhMj/02S3omIwxHxR0k/lbS6gT4GXkS8Kun98xavlrSpuL9JY/95\n+q5FbwMhIk5ExBvF/dOSzk0r3+i2K+mrEU2E/2pJvx33eFQNboAJhKRf2d5te6jpZiYw59y0aMXt\nVQ33c76207b303nTyg/MtutmuvuqNRH+iaYSGqTzjbdGxFcl/Z2kbxe7t+jMjyR9WWNzOJ6Q9P0m\nmymmld8i6TsR8fsmexlvgr4a2W5NhH9U0vxxj+dJOt5AHxOKiOPF7SlJWzV2mDJITp6bIbm4PdVw\nP38SEScj4pOI+FTSj9Xgtiumld8iaXNEvFAsbnzbTdRXU9utifDvkrTI9kLbMyTdJWlbA318ju1L\nig9iZPsSSSs0eFOPb5O0rri/TtJLDfbyGYMybXuraeXV8LYbtOnuG7nCrziV8R+SpkvaEBHf63sT\nE7D9Fxob7aWxrzv/pMnebD8naZnGvvJ5UtIjkl6U9LykP5d0VNKaiOj7B28telumC5y2vabeWk0r\nv1MNbrsqp7uvpB8u7wVy4go/ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0jq/wB+qL8ApgUmhwAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a27aee390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.title(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.8396 - acc: 0.7242\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 7s 121us/step - loss: 0.5785 - acc: 0.8137\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4936 - acc: 0.8416\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 7s 121us/step - loss: 0.4462 - acc: 0.8579\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 7s 121us/step - loss: 0.4142 - acc: 0.8704\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 7s 126us/step - loss: 0.3930 - acc: 0.8758\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 7s 127us/step - loss: 0.3831 - acc: 0.8797\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.3591 - acc: 0.8895\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.3529 - acc: 0.8898\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 7s 126us/step - loss: 0.3385 - acc: 0.8949\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Maxpool2D\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2d(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3,3)), activation='relu')\n",
    "model.add(MacPool2d(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
