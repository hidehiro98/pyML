{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニングでタッチの達也と和哉の分類をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 画像のリサイズ\n",
    "参考: https://note.nkmk.me/python-pillow-image-resize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../images/touch_comic/original/*.png')\n",
    "\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    img_resize = img.resize((128, 128))\n",
    "    ftitle, fext = os.path.splitext(f)\n",
    "    img_resize.save(ftitle + '_resized' + fext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augumentationを用いて学習データを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAnFQiIiISCAOChEREQnEQSEiIiKB/x9Y9szNzozHzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa6b16649e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = load_img(\"../images/touch_comic/original/kazuya1_resized.png\", grayscale=True)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128, 128, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "ftitle, fext = os.path.splitext(glob.glob(\"../images/touch_comic/original/kazuya1_resized.png\")[0])\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='.', save_prefix=ftitle, save_format='png'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全ての画像を処理  いらない？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../images/touch_comic/*_resized.png')\n",
    "\n",
    "for f in files:\n",
    "    ftitle, fext = os.path.splitext(f)\n",
    "    img = load_img(f, grayscale=True)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir='.', save_prefix=ftitle, save_format='png'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を取り込む 再開はここから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.backend(), K.image_dim_ordering()\n",
    "\n",
    "img_array = []\n",
    "label = []\n",
    "\n",
    "files = glob.glob('../images/touch_comic/*.png')\n",
    "\n",
    "for f in files:\n",
    "    img_array.append(img_to_array(load_img(f, grayscale=True)))\n",
    "    label.append(re.findall(r\"(kazuya|tatsuya)\", f)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nparray = np.array(img_array) / 255\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tatsuya'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 1 0 0\n",
      " 1 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0\n",
      " 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1\n",
      " 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0\n",
      " 1 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0\n",
      " 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1\n",
      " 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1\n",
      " 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1]\n",
      "[[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(label)\n",
    "print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_nparray, onehot_encoded, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 128, 128, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation画像読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.backend(), K.image_dim_ordering()\n",
    "\n",
    "img_array = []\n",
    "label = []\n",
    "\n",
    "files = glob.glob('../images/touch_comic/*.png')\n",
    "\n",
    "for f in files:\n",
    "    img_array.append(img_to_array(load_img(f, grayscale=True)))\n",
    "    label.append(re.findall(r\"(kazuya|tatsuya)\", f)[0])\n",
    "    \n",
    "X_test = np.array(img_array) / 255\n",
    "label = np.array(label)\n",
    "\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(label)\n",
    "\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "y_test = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 2s - loss: 0.8104 - acc: 0.5625 - val_loss: 0.8984 - val_acc: 0.5000\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s - loss: 1.0598 - acc: 0.5781 - val_loss: 0.6856 - val_acc: 0.5250\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s - loss: 0.7394 - acc: 0.5000 - val_loss: 0.6897 - val_acc: 0.5136\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s - loss: 0.6952 - acc: 0.4531 - val_loss: 0.6908 - val_acc: 0.5864\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s - loss: 0.6913 - acc: 0.5156 - val_loss: 0.6912 - val_acc: 0.5818\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s - loss: 0.6956 - acc: 0.6094 - val_loss: 0.6915 - val_acc: 0.5000\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 1s - loss: 0.6976 - acc: 0.5186 - val_loss: 0.6918 - val_acc: 0.5068\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s - loss: 0.6913 - acc: 0.5781 - val_loss: 0.6918 - val_acc: 0.5705\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s - loss: 0.6902 - acc: 0.5469 - val_loss: 0.6907 - val_acc: 0.6455\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s - loss: 0.6825 - acc: 0.6250 - val_loss: 0.6879 - val_acc: 0.6500\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s - loss: 0.6858 - acc: 0.5625 - val_loss: 0.6819 - val_acc: 0.5409\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s - loss: 0.6810 - acc: 0.5312 - val_loss: 0.6854 - val_acc: 0.5205\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s - loss: 0.7174 - acc: 0.4634 - val_loss: 0.6804 - val_acc: 0.5364\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s - loss: 0.7260 - acc: 0.3281 - val_loss: 0.6819 - val_acc: 0.6614\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s - loss: 0.6840 - acc: 0.5625 - val_loss: 0.6864 - val_acc: 0.5727\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s - loss: 0.6827 - acc: 0.4844 - val_loss: 0.6881 - val_acc: 0.5114\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s - loss: 0.6887 - acc: 0.5000 - val_loss: 0.6872 - val_acc: 0.5114\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s - loss: 0.6941 - acc: 0.4688 - val_loss: 0.6862 - val_acc: 0.5477\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s - loss: 0.6866 - acc: 0.6094 - val_loss: 0.6848 - val_acc: 0.6227\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s - loss: 0.6894 - acc: 0.5372 - val_loss: 0.6831 - val_acc: 0.6864\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s - loss: 0.6798 - acc: 0.6250 - val_loss: 0.6794 - val_acc: 0.5568\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s - loss: 0.6920 - acc: 0.5156 - val_loss: 0.6766 - val_acc: 0.5545\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s - loss: 0.6583 - acc: 0.6250 - val_loss: 0.6724 - val_acc: 0.5545\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s - loss: 0.6870 - acc: 0.5469 - val_loss: 0.6613 - val_acc: 0.6068\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s - loss: 0.6512 - acc: 0.6094 - val_loss: 0.6646 - val_acc: 0.5727\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s - loss: 0.7051 - acc: 0.5887 - val_loss: 0.6471 - val_acc: 0.7091\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s - loss: 0.6646 - acc: 0.6406 - val_loss: 0.6479 - val_acc: 0.5614\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s - loss: 0.6514 - acc: 0.6250 - val_loss: 0.6428 - val_acc: 0.5795\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s - loss: 0.7484 - acc: 0.4375 - val_loss: 0.6423 - val_acc: 0.6886\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s - loss: 0.6747 - acc: 0.5000 - val_loss: 0.6515 - val_acc: 0.6886\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s - loss: 0.6754 - acc: 0.6250 - val_loss: 0.6535 - val_acc: 0.6909\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s - loss: 0.6308 - acc: 0.6562 - val_loss: 0.6464 - val_acc: 0.7068\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s - loss: 0.6500 - acc: 0.6600 - val_loss: 0.6338 - val_acc: 0.7023\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s - loss: 0.6358 - acc: 0.6562 - val_loss: 0.6238 - val_acc: 0.6818\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s - loss: 0.6551 - acc: 0.5938 - val_loss: 0.6174 - val_acc: 0.6341\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s - loss: 0.6637 - acc: 0.5938 - val_loss: 0.6134 - val_acc: 0.6250\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s - loss: 0.6657 - acc: 0.5469 - val_loss: 0.5995 - val_acc: 0.7295\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s - loss: 0.6788 - acc: 0.6250 - val_loss: 0.6253 - val_acc: 0.6227\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s - loss: 0.6186 - acc: 0.6594 - val_loss: 0.6425 - val_acc: 0.5159\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s - loss: 0.6339 - acc: 0.6562 - val_loss: 0.6359 - val_acc: 0.5250\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s - loss: 0.6067 - acc: 0.6250 - val_loss: 0.6236 - val_acc: 0.5750\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s - loss: 0.6579 - acc: 0.6719 - val_loss: 0.6052 - val_acc: 0.6864\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s - loss: 0.6555 - acc: 0.6250 - val_loss: 0.5961 - val_acc: 0.7295\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s - loss: 0.6657 - acc: 0.6406 - val_loss: 0.6133 - val_acc: 0.5955\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s - loss: 0.5798 - acc: 0.7031 - val_loss: 0.6482 - val_acc: 0.5500\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s - loss: 0.6310 - acc: 0.6973 - val_loss: 0.6037 - val_acc: 0.6136\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s - loss: 0.6970 - acc: 0.5469 - val_loss: 0.5860 - val_acc: 0.8318\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s - loss: 0.6240 - acc: 0.6562 - val_loss: 0.6026 - val_acc: 0.6318\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s - loss: 0.6229 - acc: 0.6250 - val_loss: 0.5993 - val_acc: 0.6341\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s - loss: 0.5989 - acc: 0.7188 - val_loss: 0.5674 - val_acc: 0.7682\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s - loss: 0.6271 - acc: 0.6094 - val_loss: 0.5367 - val_acc: 0.8409\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s - loss: 0.5322 - acc: 0.7494 - val_loss: 0.5364 - val_acc: 0.7091\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s - loss: 0.6105 - acc: 0.7344 - val_loss: 0.4867 - val_acc: 0.8250\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s - loss: 0.6108 - acc: 0.6406 - val_loss: 0.4912 - val_acc: 0.8045\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s - loss: 0.5424 - acc: 0.6719 - val_loss: 0.4729 - val_acc: 0.8477\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s - loss: 0.6563 - acc: 0.5625 - val_loss: 0.4853 - val_acc: 0.8659\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s - loss: 0.5379 - acc: 0.7344 - val_loss: 0.4704 - val_acc: 0.8591\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s - loss: 0.5439 - acc: 0.7656 - val_loss: 0.4465 - val_acc: 0.8795\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s - loss: 0.5745 - acc: 0.7314 - val_loss: 0.4363 - val_acc: 0.8955\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s - loss: 0.4833 - acc: 0.7812 - val_loss: 0.5552 - val_acc: 0.6409\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s - loss: 0.7109 - acc: 0.6406 - val_loss: 0.4715 - val_acc: 0.8409\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s - loss: 0.5784 - acc: 0.6719 - val_loss: 0.6292 - val_acc: 0.5773\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s - loss: 0.6973 - acc: 0.5625 - val_loss: 0.5679 - val_acc: 0.6545\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s - loss: 0.5556 - acc: 0.6875 - val_loss: 0.5364 - val_acc: 0.8591\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s - loss: 0.5314 - acc: 0.9280 - val_loss: 0.4988 - val_acc: 0.8159\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s - loss: 0.5239 - acc: 0.7031 - val_loss: 0.4645 - val_acc: 0.8136\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s - loss: 0.5548 - acc: 0.7500 - val_loss: 0.4294 - val_acc: 0.8341\n",
      "Epoch 68/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s - loss: 0.5780 - acc: 0.6719 - val_loss: 0.4565 - val_acc: 0.7750\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s - loss: 0.5826 - acc: 0.6719 - val_loss: 0.4023 - val_acc: 0.8386\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s - loss: 0.5589 - acc: 0.7188 - val_loss: 0.4613 - val_acc: 0.7705\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s - loss: 0.5425 - acc: 0.7344 - val_loss: 0.4168 - val_acc: 0.8523\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s - loss: 0.4900 - acc: 0.7506 - val_loss: 0.4165 - val_acc: 0.8636\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s - loss: 0.4369 - acc: 0.8438 - val_loss: 0.4260 - val_acc: 0.8045\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s - loss: 0.4566 - acc: 0.7656 - val_loss: 0.3526 - val_acc: 0.9045\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s - loss: 0.4017 - acc: 0.8281 - val_loss: 0.3441 - val_acc: 0.8568\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s - loss: 0.4014 - acc: 0.7812 - val_loss: 0.2993 - val_acc: 0.8955\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s - loss: 0.4790 - acc: 0.7656 - val_loss: 0.3100 - val_acc: 0.8955\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s - loss: 0.3381 - acc: 0.8741 - val_loss: 0.3651 - val_acc: 0.8386\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s - loss: 0.4516 - acc: 0.8438 - val_loss: 0.3814 - val_acc: 0.8091\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s - loss: 0.5637 - acc: 0.7031 - val_loss: 0.3061 - val_acc: 0.8682\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s - loss: 0.4460 - acc: 0.7188 - val_loss: 0.4108 - val_acc: 0.7659\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s - loss: 0.6496 - acc: 0.7344 - val_loss: 0.3409 - val_acc: 0.9182\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s - loss: 0.4179 - acc: 0.8281 - val_loss: 0.4574 - val_acc: 0.7295\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s - loss: 0.4897 - acc: 0.7812 - val_loss: 0.5011 - val_acc: 0.6977\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s - loss: 0.5339 - acc: 0.6954 - val_loss: 0.4540 - val_acc: 0.7523\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s - loss: 0.5049 - acc: 0.7344 - val_loss: 0.3893 - val_acc: 0.8705\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s - loss: 0.4242 - acc: 0.8594 - val_loss: 0.3363 - val_acc: 0.9000\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s - loss: 0.3752 - acc: 0.8125 - val_loss: 0.3595 - val_acc: 0.8227\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s - loss: 0.4864 - acc: 0.7500 - val_loss: 0.2834 - val_acc: 0.9159\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s - loss: 0.4352 - acc: 0.7969 - val_loss: 0.2746 - val_acc: 0.9227\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s - loss: 0.4060 - acc: 0.7680 - val_loss: 0.2782 - val_acc: 0.9205\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s - loss: 0.4657 - acc: 0.7812 - val_loss: 0.2582 - val_acc: 0.9432\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s - loss: 0.4226 - acc: 0.7656 - val_loss: 0.2491 - val_acc: 0.9250\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s - loss: 0.2474 - acc: 0.9375 - val_loss: 0.2263 - val_acc: 0.9091\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s - loss: 0.3799 - acc: 0.8438 - val_loss: 0.1756 - val_acc: 0.9568\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s - loss: 0.3942 - acc: 0.8281 - val_loss: 0.3442 - val_acc: 0.8477\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s - loss: 0.5446 - acc: 0.7969 - val_loss: 0.2726 - val_acc: 0.8909\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s - loss: 0.2433 - acc: 0.8927 - val_loss: 0.2704 - val_acc: 0.8727\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s - loss: 0.4488 - acc: 0.8125 - val_loss: 0.3030 - val_acc: 0.8477\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s - loss: 0.4447 - acc: 0.7969 - val_loss: 0.2833 - val_acc: 0.9250\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s - loss: 0.3933 - acc: 0.7969 - val_loss: 0.3346 - val_acc: 0.8727\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s - loss: 0.5153 - acc: 0.7188 - val_loss: 0.3109 - val_acc: 0.9023\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s - loss: 0.3501 - acc: 0.9062 - val_loss: 0.2752 - val_acc: 0.9318\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s - loss: 0.3326 - acc: 0.9107 - val_loss: 0.2809 - val_acc: 0.9045\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s - loss: 0.4311 - acc: 0.8125 - val_loss: 0.2345 - val_acc: 0.9318\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s - loss: 0.3571 - acc: 0.8438 - val_loss: 0.2035 - val_acc: 0.9636\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s - loss: 0.3467 - acc: 0.8750 - val_loss: 0.2605 - val_acc: 0.8932\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s - loss: 0.2986 - acc: 0.8281 - val_loss: 0.1626 - val_acc: 0.9682\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s - loss: 0.3723 - acc: 0.8125 - val_loss: 0.1476 - val_acc: 0.9477\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s - loss: 0.2837 - acc: 0.8281 - val_loss: 0.1297 - val_acc: 0.9682\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s - loss: 0.1374 - acc: 0.9820 - val_loss: 0.1262 - val_acc: 0.9659\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s - loss: 0.3473 - acc: 0.7969 - val_loss: 0.1279 - val_acc: 0.9682\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s - loss: 0.2658 - acc: 0.8906 - val_loss: 0.1250 - val_acc: 0.9659\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s - loss: 0.2889 - acc: 0.8438 - val_loss: 0.1111 - val_acc: 0.9750\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s - loss: 0.2208 - acc: 0.8750 - val_loss: 0.1069 - val_acc: 0.9750\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s - loss: 0.2408 - acc: 0.9219 - val_loss: 0.1441 - val_acc: 0.9523\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s - loss: 0.3048 - acc: 0.9107 - val_loss: 0.0786 - val_acc: 0.9864\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s - loss: 0.3961 - acc: 0.8594 - val_loss: 0.0995 - val_acc: 0.9795\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s - loss: 0.1974 - acc: 0.9219 - val_loss: 0.1263 - val_acc: 0.9614\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s - loss: 0.3010 - acc: 0.8438 - val_loss: 0.1800 - val_acc: 0.9318\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s - loss: 0.2701 - acc: 0.9062 - val_loss: 0.1552 - val_acc: 0.9614\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s - loss: 0.3202 - acc: 0.8594 - val_loss: 0.1289 - val_acc: 0.9818\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s - loss: 0.3451 - acc: 0.8594 - val_loss: 0.1184 - val_acc: 0.9909\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s - loss: 0.2370 - acc: 0.9100 - val_loss: 0.1083 - val_acc: 0.9909\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s - loss: 0.3682 - acc: 0.8281 - val_loss: 0.1404 - val_acc: 0.9705\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s - loss: 0.2901 - acc: 0.8750 - val_loss: 0.0976 - val_acc: 0.9864\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s - loss: 0.3117 - acc: 0.8438 - val_loss: 0.0907 - val_acc: 0.9864\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s - loss: 0.1979 - acc: 0.9375 - val_loss: 0.0940 - val_acc: 0.9864\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s - loss: 0.1045 - acc: 0.9844 - val_loss: 0.0804 - val_acc: 0.9864\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s - loss: 0.2561 - acc: 0.8747 - val_loss: 0.0619 - val_acc: 0.9955\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s - loss: 0.1340 - acc: 0.9219 - val_loss: 0.0774 - val_acc: 0.9818\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s - loss: 0.2511 - acc: 0.8906 - val_loss: 0.1870 - val_acc: 0.9182\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s - loss: 0.4261 - acc: 0.7812 - val_loss: 0.0896 - val_acc: 0.9750\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s - loss: 0.2549 - acc: 0.8750 - val_loss: 0.1114 - val_acc: 0.9705\n",
      "Epoch 135/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s - loss: 0.1969 - acc: 0.9531 - val_loss: 0.1046 - val_acc: 0.9841\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s - loss: 0.1872 - acc: 0.9219 - val_loss: 0.1932 - val_acc: 0.9341\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s - loss: 0.1948 - acc: 0.9280 - val_loss: 0.1765 - val_acc: 0.9386\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s - loss: 0.2204 - acc: 0.9375 - val_loss: 0.1142 - val_acc: 0.9659\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s - loss: 0.3117 - acc: 0.8906 - val_loss: 0.0946 - val_acc: 0.9750\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s - loss: 0.1764 - acc: 0.9531 - val_loss: 0.0886 - val_acc: 0.9750\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s - loss: 0.1664 - acc: 0.9375 - val_loss: 0.0958 - val_acc: 0.9727\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s - loss: 0.2255 - acc: 0.8906 - val_loss: 0.0811 - val_acc: 0.9795\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s - loss: 0.1518 - acc: 0.9113 - val_loss: 0.0740 - val_acc: 0.9841\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s - loss: 0.2491 - acc: 0.8906 - val_loss: 0.0713 - val_acc: 0.9818\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s - loss: 0.1225 - acc: 0.9531 - val_loss: 0.1159 - val_acc: 0.9614\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s - loss: 0.2517 - acc: 0.9062 - val_loss: 0.0677 - val_acc: 0.9841\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s - loss: 0.1496 - acc: 0.9375 - val_loss: 0.0550 - val_acc: 0.9909\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s - loss: 0.1697 - acc: 0.9531 - val_loss: 0.0520 - val_acc: 0.9955\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s - loss: 0.2508 - acc: 0.8906 - val_loss: 0.0870 - val_acc: 0.9705\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s - loss: 0.2487 - acc: 0.8573 - val_loss: 0.0415 - val_acc: 0.9955\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s - loss: 0.1396 - acc: 0.9688 - val_loss: 0.0410 - val_acc: 0.9955\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s - loss: 0.1811 - acc: 0.9219 - val_loss: 0.0502 - val_acc: 0.9909\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s - loss: 0.2305 - acc: 0.9062 - val_loss: 0.0529 - val_acc: 0.9909\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s - loss: 0.1290 - acc: 0.9375 - val_loss: 0.0343 - val_acc: 1.0000\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s - loss: 0.2146 - acc: 0.9375 - val_loss: 0.0408 - val_acc: 0.9955\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s - loss: 0.1529 - acc: 0.9460 - val_loss: 0.0559 - val_acc: 0.9909\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s - loss: 0.1772 - acc: 0.9062 - val_loss: 0.0909 - val_acc: 0.9750\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s - loss: 0.3329 - acc: 0.8750 - val_loss: 0.0471 - val_acc: 0.9977\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s - loss: 0.1387 - acc: 0.9375 - val_loss: 0.0470 - val_acc: 0.9977\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s - loss: 0.0757 - acc: 0.9844 - val_loss: 0.0422 - val_acc: 0.9955\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s - loss: 0.1325 - acc: 0.9844 - val_loss: 0.0505 - val_acc: 0.9909\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s - loss: 0.1977 - acc: 0.9062 - val_loss: 0.0729 - val_acc: 0.9818\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s - loss: 0.0983 - acc: 0.9640 - val_loss: 0.0707 - val_acc: 0.9841\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s - loss: 0.2497 - acc: 0.8750 - val_loss: 0.0533 - val_acc: 1.0000\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s - loss: 0.2671 - acc: 0.8750 - val_loss: 0.0378 - val_acc: 1.0000\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s - loss: 0.1353 - acc: 0.9531 - val_loss: 0.0529 - val_acc: 0.9932\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s - loss: 0.0626 - acc: 1.0000 - val_loss: 0.1457 - val_acc: 0.9318\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s - loss: 0.1429 - acc: 0.9375 - val_loss: 0.1085 - val_acc: 0.9545\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s - loss: 0.2253 - acc: 0.9280 - val_loss: 0.0311 - val_acc: 0.9977\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s - loss: 0.2584 - acc: 0.8750 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s - loss: 0.1469 - acc: 0.9375 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s - loss: 0.1524 - acc: 0.9531 - val_loss: 0.0403 - val_acc: 0.9932\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s - loss: 0.1001 - acc: 0.9688 - val_loss: 0.0630 - val_acc: 0.9841\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s - loss: 0.1786 - acc: 0.9375 - val_loss: 0.0441 - val_acc: 0.9886\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s - loss: 0.0628 - acc: 0.9844 - val_loss: 0.0349 - val_acc: 0.9955\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s - loss: 0.1841 - acc: 0.9287 - val_loss: 0.0448 - val_acc: 0.9909\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s - loss: 0.1785 - acc: 0.9062 - val_loss: 0.0288 - val_acc: 0.9977\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s - loss: 0.1029 - acc: 0.9844 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s - loss: 0.1080 - acc: 0.9688 - val_loss: 0.0220 - val_acc: 1.0000\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s - loss: 0.1438 - acc: 0.9375 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s - loss: 0.1215 - acc: 0.9375 - val_loss: 0.0434 - val_acc: 0.9886\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s - loss: 0.1531 - acc: 0.9113 - val_loss: 0.0254 - val_acc: 0.9955\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s - loss: 0.1068 - acc: 0.9688 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s - loss: 0.1470 - acc: 0.9375 - val_loss: 0.0195 - val_acc: 0.9977\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s - loss: 0.1432 - acc: 0.9219 - val_loss: 0.0361 - val_acc: 0.9932\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s - loss: 0.1033 - acc: 0.9531 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s - loss: 0.1380 - acc: 0.9531 - val_loss: 0.0370 - val_acc: 0.9977\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s - loss: 0.3803 - acc: 0.8750 - val_loss: 0.1403 - val_acc: 0.9386\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s - loss: 0.5488 - acc: 0.7847 - val_loss: 0.1593 - val_acc: 0.9227\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s - loss: 0.1282 - acc: 0.9531 - val_loss: 0.0451 - val_acc: 1.0000\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s - loss: 0.1750 - acc: 0.9531 - val_loss: 0.0868 - val_acc: 0.9909\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s - loss: 0.1980 - acc: 0.9219 - val_loss: 0.0823 - val_acc: 0.9932\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s - loss: 0.1926 - acc: 0.9375 - val_loss: 0.0477 - val_acc: 0.9977\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s - loss: 0.2003 - acc: 0.9531 - val_loss: 0.0920 - val_acc: 0.9750\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s - loss: 0.1304 - acc: 0.9640 - val_loss: 0.1093 - val_acc: 0.9659\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s - loss: 0.2452 - acc: 0.9219 - val_loss: 0.0648 - val_acc: 0.9841\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s - loss: 0.0846 - acc: 0.9844 - val_loss: 0.0472 - val_acc: 0.9886\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s - loss: 0.1599 - acc: 0.9219 - val_loss: 0.0509 - val_acc: 0.9886\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s - loss: 0.1639 - acc: 0.9688 - val_loss: 0.0450 - val_acc: 0.9909\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s - loss: 0.2066 - acc: 0.9375 - val_loss: 0.0330 - val_acc: 0.9977\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s - loss: 0.1786 - acc: 0.9375 - val_loss: 0.0449 - val_acc: 0.9886\n",
      "Epoch 202/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s - loss: 0.1206 - acc: 0.9287 - val_loss: 0.0367 - val_acc: 0.9955\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s - loss: 0.1296 - acc: 0.9844 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s - loss: 0.1662 - acc: 0.9062 - val_loss: 0.0277 - val_acc: 1.0000\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s - loss: 0.1426 - acc: 0.9219 - val_loss: 0.0339 - val_acc: 0.9955\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s - loss: 0.1068 - acc: 0.9688 - val_loss: 0.0421 - val_acc: 0.9932\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s - loss: 0.1178 - acc: 0.9531 - val_loss: 0.0275 - val_acc: 0.9977\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s - loss: 0.1799 - acc: 0.9287 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s - loss: 0.1595 - acc: 0.9219 - val_loss: 0.0225 - val_acc: 1.0000\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s - loss: 0.1060 - acc: 0.9844 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s - loss: 0.0739 - acc: 0.9844 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s - loss: 0.1064 - acc: 0.9688 - val_loss: 0.0318 - val_acc: 0.9932\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s - loss: 0.1463 - acc: 0.9219 - val_loss: 0.0222 - val_acc: 0.9977\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s - loss: 0.1027 - acc: 0.9531 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s - loss: 0.1358 - acc: 0.9640 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s - loss: 0.1543 - acc: 0.9531 - val_loss: 0.0166 - val_acc: 1.0000\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s - loss: 0.0782 - acc: 0.9531 - val_loss: 0.0356 - val_acc: 0.9864\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s - loss: 0.1135 - acc: 0.9688 - val_loss: 0.0405 - val_acc: 0.9864\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s - loss: 0.1168 - acc: 0.9531 - val_loss: 0.0203 - val_acc: 0.9932\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s - loss: 0.0740 - acc: 0.9531 - val_loss: 0.0123 - val_acc: 1.0000\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s - loss: 0.0869 - acc: 0.9820 - val_loss: 0.0178 - val_acc: 1.0000\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s - loss: 0.2209 - acc: 0.9375 - val_loss: 0.0194 - val_acc: 1.0000\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s - loss: 0.1069 - acc: 0.9688 - val_loss: 0.0140 - val_acc: 0.9977\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s - loss: 0.0865 - acc: 0.9531 - val_loss: 0.0379 - val_acc: 0.9932\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s - loss: 0.1137 - acc: 0.9688 - val_loss: 0.0457 - val_acc: 0.9818\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s - loss: 0.1895 - acc: 0.9375 - val_loss: 0.0146 - val_acc: 0.9977\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s - loss: 0.0439 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 0.9773\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s - loss: 0.2789 - acc: 0.8580 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s - loss: 0.1679 - acc: 0.9375 - val_loss: 0.0412 - val_acc: 0.9864\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s - loss: 0.2298 - acc: 0.9375 - val_loss: 0.0715 - val_acc: 0.9682\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s - loss: 0.2056 - acc: 0.9375 - val_loss: 0.0302 - val_acc: 0.9955\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s - loss: 0.0643 - acc: 0.9844 - val_loss: 0.0244 - val_acc: 0.9977\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s - loss: 0.0798 - acc: 0.9688 - val_loss: 0.0366 - val_acc: 1.0000\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s - loss: 0.2905 - acc: 0.9113 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s - loss: 0.1145 - acc: 0.9688 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s - loss: 0.1810 - acc: 0.9062 - val_loss: 0.0222 - val_acc: 1.0000\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s - loss: 0.0633 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s - loss: 0.1207 - acc: 0.9688 - val_loss: 0.0323 - val_acc: 1.0000\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s - loss: 0.0882 - acc: 0.9688 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s - loss: 0.1145 - acc: 0.9531 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s - loss: 0.1177 - acc: 0.9467 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s - loss: 0.0636 - acc: 0.9688 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s - loss: 0.1537 - acc: 0.9531 - val_loss: 0.0143 - val_acc: 0.9977\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s - loss: 0.0616 - acc: 0.9688 - val_loss: 0.0176 - val_acc: 0.9955\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s - loss: 0.1879 - acc: 0.9531 - val_loss: 0.0139 - val_acc: 0.9977\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s - loss: 0.1726 - acc: 0.9375 - val_loss: 0.0144 - val_acc: 0.9977\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s - loss: 0.0561 - acc: 0.9646 - val_loss: 0.0157 - val_acc: 0.9977\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s - loss: 0.1454 - acc: 0.9688 - val_loss: 0.0138 - val_acc: 0.9977\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s - loss: 0.0659 - acc: 0.9844 - val_loss: 0.0177 - val_acc: 0.9955\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s - loss: 0.1838 - acc: 0.9531 - val_loss: 0.0149 - val_acc: 0.9955\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s - loss: 0.0445 - acc: 0.9844 - val_loss: 0.0107 - val_acc: 0.9977\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s - loss: 0.0324 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s - loss: 0.1045 - acc: 0.9531 - val_loss: 0.0233 - val_acc: 0.9955\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s - loss: 0.1926 - acc: 0.9467 - val_loss: 0.0227 - val_acc: 0.9932\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s - loss: 0.0973 - acc: 0.9531 - val_loss: 0.0623 - val_acc: 0.9841\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s - loss: 0.2143 - acc: 0.9062 - val_loss: 0.0154 - val_acc: 0.9977\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s - loss: 0.0469 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 0.9977\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s - loss: 0.0542 - acc: 0.9688 - val_loss: 0.0362 - val_acc: 0.9977\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s - loss: 0.1166 - acc: 0.9531 - val_loss: 0.0302 - val_acc: 0.9977\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s - loss: 0.2344 - acc: 0.9113 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s - loss: 0.0447 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s - loss: 0.1172 - acc: 0.9375 - val_loss: 0.0238 - val_acc: 0.9977\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s - loss: 0.0709 - acc: 0.9688 - val_loss: 0.0282 - val_acc: 0.9977\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s - loss: 0.1021 - acc: 0.9688 - val_loss: 0.0253 - val_acc: 0.9977\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s - loss: 0.0798 - acc: 0.9844 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s - loss: 0.0907 - acc: 0.9531 - val_loss: 0.0136 - val_acc: 1.0000\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s - loss: 0.1122 - acc: 0.9467 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s - loss: 0.0481 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 269/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s - loss: 0.1863 - acc: 0.9219 - val_loss: 0.0081 - val_acc: 1.0000\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s - loss: 0.0517 - acc: 0.9844 - val_loss: 0.0156 - val_acc: 1.0000\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 0.9955\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s - loss: 0.1020 - acc: 0.9844 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s - loss: 0.1099 - acc: 0.9820 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s - loss: 0.0457 - acc: 0.9844 - val_loss: 0.0093 - val_acc: 0.9977\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s - loss: 0.0862 - acc: 0.9688 - val_loss: 0.0070 - val_acc: 0.9977\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s - loss: 0.0210 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s - loss: 0.0796 - acc: 0.9531 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s - loss: 0.1095 - acc: 0.9688 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s - loss: 0.0796 - acc: 0.9531 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s - loss: 0.1231 - acc: 0.9646 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s - loss: 0.1738 - acc: 0.9531 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s - loss: 0.1060 - acc: 0.9844 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s - loss: 0.0294 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s - loss: 0.1491 - acc: 0.9531 - val_loss: 0.0074 - val_acc: 1.0000\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s - loss: 0.0795 - acc: 0.9844 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s - loss: 0.0725 - acc: 0.9467 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s - loss: 0.0479 - acc: 0.9844 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s - loss: 0.0855 - acc: 0.9688 - val_loss: 0.0132 - val_acc: 1.0000\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9955\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s - loss: 0.1302 - acc: 0.9219 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s - loss: 0.1679 - acc: 0.9688 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s - loss: 0.1289 - acc: 0.9646 - val_loss: 0.0099 - val_acc: 0.9955\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s - loss: 0.1972 - acc: 0.9062 - val_loss: 0.0089 - val_acc: 0.9955\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s - loss: 0.0540 - acc: 0.9844 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s - loss: 0.0783 - acc: 0.9844 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s - loss: 0.0677 - acc: 0.9844 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s - loss: 0.0923 - acc: 0.9688 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s - loss: 0.0636 - acc: 0.9646 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s - loss: 0.0869 - acc: 0.9531 - val_loss: 0.0032 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53e4f382b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=2,\n",
    "                        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの保存とロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "\n",
    "model.save('../images/touch_comic/touch.h5')\n",
    "print('Saved trained model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを使って試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../images/touch_comic/test/Screen*.png')\n",
    "\n",
    "for f in files:\n",
    "    img = Image.open(f)\n",
    "    img_resize = img.resize((128, 128))\n",
    "    ftitle, fext = os.path.splitext(f)\n",
    "    ftitle = ftitle.replace('Screen', '')\n",
    "    img_resize.save(ftitle + '_resized' + fext)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../images/touch_comic/test/ Shot 2018-02-10 at 16.33.44_resized_resized.png',\n",
       " '../images/touch_comic/test/Screen Shot 2018-02-10 at 16.33.44_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 16.33.44_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 16.33.54_resized_resized.png',\n",
       " '../images/touch_comic/test/Screen Shot 2018-02-10 at 16.33.54_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 20.44.51_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 16.33.54_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 16.33.59_resized_resized.png',\n",
       " '../images/touch_comic/test/Screen Shot 2018-02-10 at 16.33.59_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 20.44.24_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 20.44.35_resized.png',\n",
       " '../images/touch_comic/test/ Shot 2018-02-10 at 16.33.59_resized.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = []\n",
    "label_test = []\n",
    "\n",
    "files = glob.glob('../images/touch_comic/test/*_resized.png')\n",
    "\n",
    "for f in files:\n",
    "    img_test.append(img_to_array(load_img(f, grayscale=True)))\n",
    "#     label_test.append(re.findall(r\"(kazuya|tatsuya)\", f)[0])\n",
    "    \n",
    "img_nparray_test = np.array(img_test) / 255\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# integer_encoded = label_encoder.fit_transform(label_test)\n",
    "\n",
    "# # binary encode\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "# onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "predict = model.predict(img_nparray_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.77439922e-04,   9.99022603e-01],\n",
       "       [  9.77439922e-04,   9.99022603e-01],\n",
       "       [  9.77439922e-04,   9.99022603e-01],\n",
       "       [  1.00440651e-04,   9.99899507e-01],\n",
       "       [  1.00440651e-04,   9.99899507e-01],\n",
       "       [  2.62083108e-06,   9.99997377e-01],\n",
       "       [  1.00440651e-04,   9.99899507e-01],\n",
       "       [  7.51961708e-01,   2.48038352e-01],\n",
       "       [  7.51961708e-01,   2.48038352e-01],\n",
       "       [  1.32539473e-03,   9.98674631e-01],\n",
       "       [  5.93333971e-05,   9.99940634e-01],\n",
       "       [  7.51961708e-01,   2.48038352e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
